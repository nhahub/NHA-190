# -*- coding: utf-8 -*-
"""Student Dropout Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R8iloJT4ET1d9_OvB26OswNdbv9ikMbm
"""



"""# This machine learning project predicts whether a student will drop out or successfully complete their academic program. The full workflow follows these steps exactly as implemented in your code:

# ðŸ”¹ 1. Importing Libraries & Loading the Dataset

All required libraries (Pandas, NumPy, Sklearn, Seaborn, Matplotlib, SciPy) are imported.
The student dataset is loaded using pd.read_csv() and stored in df.

# ðŸ”¹ 2. Initial Data Analysis

You perform basic inspection using:

df.head(), df.info(), df.describe(), df.isna().sum()
plus histograms and count plots to understand variable distributions.

# ðŸ”¹ 3. Copying Dataset for Processing

s_df = df.copy()
A safe working copy is created so the original remains unchanged.

# ðŸ”¹ 4. Exploring Categorical Columns

Using multiple value_counts() you inspect:

Marital status

Application mode

Course

Parentsâ€™ qualification

Curricular units (1st/2nd semester)

Economic indicators (Unemployment, Inflation, GDP)

This helps identify distributions and rare labels.

# ðŸ”¹ 5. Encoding Target Label

LabelEncoder() converts the text Target values into numeric codes.
Later, â€œEnrolledâ€ is removed and the remaining target is mapped to:

1 â†’ Academic Success

0 â†’ Dropout

# ðŸ”¹ 6. Outlier Detection & Removal

Z-scores are computed for numeric columns.
Rows with |z| > 3 are removed to reduce noise and improve model learning.

# ðŸ”¹ 7. Dataset Preparation

You split the data into:

Features (X) â†’ all columns except Target

Label (y) â†’ final binary Target

# ðŸ”¹ 8. Feature Scaling

StandardScaler() is applied to produce X_processed.
This standardization improves overall model stability

# ðŸ”¹ 9. Trainâ€“Test Split

Using train_test_split():

80% Training Data

20% Testing Data

stratify=y keeps class balance intact.

# ðŸ”¹ 10. Training Multiple ML Models

You train the following algorithms:

Logistic Regression

Decision Tree

SVM (RBF)

These models are fit on X_train and y_train.

# ðŸ”¹ 12. Model Evaluation

Each model is tested using:

Accuracy

Precision

Recall

F1 Score

A model comparison table and accuracy/metric barplots are generated.

# ðŸ”¹ 13. Final Prediction & Pie Chart

The best model predicts outcomes on the test set:

0 = Dropout

1 = Academic Success

# ****Imports****
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
from matplotlib import pyplot as plt
import matplotlib.patches as mpatches
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
import os

from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from scipy import stats
from sklearn.ensemble import RandomForestClassifier
import warnings # ignores pink warnings
warnings.filterwarnings('ignore')

import os
for dirname, _, filenames in os.walk('/kaggle/input/higher-education-predictors-of-student-retention'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""# ****Load Dataset****"""

df = pd.read_csv('/content/dataset.csv')
#view the data
df.head()

# Divide the dataset to random halves
df, df_half2 = train_test_split(df, test_size=0.5, random_state=42)

# save the data to a CSV file
df.to_csv("dataset_half1.csv", index=False)
df_half2.to_csv("dataset_half2.csv", index=False)

"""# Basic Inspection"""

df.isna().sum()

df.duplicated().sum()

df.info()

"""# Summarize data â†’ show statistics cleanly"""

from pandas.io.formats.format import set_option
set_option('display.precision',2)
df.describe()

##histogram - visual representation
sns.set_theme(style = 'darkgrid')
df.hist(bins=10, figsize=(40, 35), grid=True, legend=None);

""">  how many unique values each column has."""

df.describe(include='all').loc['unique', :]

""">  Visualize how many female and male students fall into each category (Dropout, Enrolled, Graduate)."""

sns.countplot(data=df, x='Gender', hue='Target', hue_order=['Dropout', 'Enrolled', 'Graduate'])
plt.xticks(ticks=[0,1], labels=['Female','Male'])
plt.ylabel('Number of Students')
plt.show()

s_df=df.copy()
s_df.shape

"""# **Explore categorical data**"""

df.loc[:,'Marital status'].value_counts()

df.loc[:,'Application mode'].value_counts()

df.loc[:,'Application order'].value_counts()

df.loc[:,'Course'].value_counts()

df.loc[:,'Daytime/evening attendance'].value_counts()

df.loc[:,'Previous qualification'].value_counts()

df.loc[:,'Nacionality'].value_counts()

df.loc[:,"Mother's qualification"].value_counts()

df.loc[:,"Father's qualification"].value_counts()

df.loc[:,'Curricular units 1st sem (credited)'].value_counts()

df.loc[:,'Curricular units 1st sem (enrolled)'].value_counts()

df.loc[:,'Curricular units 1st sem (evaluations)'].value_counts()

df.loc[:,'Curricular units 1st sem (approved)'].value_counts()

df.loc[:,'Curricular units 1st sem (grade)'].value_counts()

df.loc[:,'Curricular units 1st sem (without evaluations)'].value_counts()

df.loc[:,'Curricular units 2nd sem (credited)'].value_counts()

df.loc[:,'Curricular units 2nd sem (enrolled)'].value_counts()

df.loc[:,'Curricular units 2nd sem (evaluations)'].value_counts()

df.loc[:,'Curricular units 2nd sem (approved)'].value_counts()

df.loc[:,'Curricular units 2nd sem (grade)'].value_counts()

df.loc[:,'Curricular units 2nd sem (without evaluations)'].value_counts()


df.loc[:,'Unemployment rate'].value_counts()


df.loc[:,'Inflation rate'].value_counts()


df.loc[:,'GDP'].value_counts()

"""# **Label Encoding**"""

s_df['Target'] = LabelEncoder().fit_transform(s_df['Target'])
s_df.loc[:,'Target'].value_counts()

"""#  ****Remove outliers****"""

# Calculating the Z-score for each data point
z_scores = np.abs(stats.zscore(s_df))

# Finding data points with a Z-score greater than 3
outliers = np.where(z_scores > 3)

# Printing the indices of the outliers
outliers

# Dropping the corresponding rows from the dataframe
out_df = s_df.drop(s_df.index[outliers[0]])

# Resetting the index of the dataframe
s_df = out_df.reset_index(drop=True)
s_df.shape
s_df

# Changing the Target to numerical Value 0 or 1.
#We are predicting if a Student is gonna Dropout or Graduate, ignoring the ones who are Enrolled.
s_df.drop(s_df[s_df["Target"]==1].index, inplace=True)
s_df.loc[:,'Target'].value_counts()

"""# Convert Target to Binary (Dropout=1 / Graduate=0)"""

# mapping integer codes to new values
mapping = {0: 1, 2: 0}
s_df["Target"] = s_df["Target"].replace(mapping)

s_df.loc[:,'Target'].value_counts()

"""> Separate Features and Label (Fix for missing x, y)"""

# X = all columns except Target
X = s_df.drop("Target", axis=1)

# y = Target
y = s_df["Target"]

print(X.shape, y.shape)

"""# ****Standardization****"""

scaler = StandardScaler()
X_processed = scaler.fit_transform(X)

print(type(X_processed), X_processed.shape)

"""# Split data into training and testing sets"""

X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y, test_size=0.2, random_state=10, stratify=y
)

print("X_train:", X_train.shape, "X_test:", X_test.shape)
print("y_train:", y_train.shape, "y_test:", y_test.shape)

"""# By Using Logistic regression

"""

lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr, zero_division=0))

"""# DecisionTree"""

dt = DecisionTreeClassifier(random_state=10)
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)

"""# SVM"""

svm = SVC(kernel='rbf', probability=True, random_state=10)
svm.fit(X_train, y_train)
y_pred_svm = svm.predict(X_test)

"""#Evaluating Models"""

# 3) Evaluate Models
models = {
    'LogisticRegression': lr,
    'DecisionTree': dt,
    'SVM_RBF': svm,
}
results = []

for name, model in models.items():
    y_pred = model.predict(X_test)
    results.append({
        'Model': name,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred, zero_division=0),
        'Recall': recall_score(y_test, y_pred, zero_division=0),
        'F1': f1_score(y_test, y_pred, zero_division=0)
    })

results_df = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)
print(results_df)

""">  Each model Precision / Recall / F1 comparison."""

# Precision / Recall / F1 comparison
metrics_melt = results_df.melt(
    id_vars='Model',
    value_vars=['Precision','Recall','F1'],
    var_name='Metric',
    value_name='Value'
)

plt.figure(figsize=(12,6))
sns.barplot(data=metrics_melt, x='Model', y='Value', hue='Metric')
plt.ylim(0.8,1)
plt.xticks(rotation=45)
plt.title('Precision / Recall / F1 Comparison')
plt.legend(loc='upper right')
plt.tight_layout()
plt.show()

"""# Final output"""

# Safety checks
if 'results_df' not in globals():
    raise ValueError("results_df is missing. Run evaluation cells first.")
if 'models' not in globals():
    raise ValueError("models dict not found. Train models first.")
if 'X_test' not in globals():
    raise ValueError("X_test not found. Run the split first.")

# Choose best model
best_row = results_df.sort_values(by='Accuracy', ascending=False).iloc[0]
best_model_name = best_row['Model']
best_accuracy = best_row['Accuracy']
print(f"Best Model: {best_model_name}  |  Accuracy: {best_accuracy:.4f}")

# Get predictions for best model
best_model = models[best_model_name]
pred = best_model.predict(X_test)

# Count predictions (0 = Dropout, 1 = Academic Success)
dropout_count = int((pred == 0).sum())
success_count = int((pred == 1).sum())
total = dropout_count + success_count
if total == 0:
    raise RuntimeError("No 0/1 predictions found for the best model.")

dropout_pct = dropout_count / total * 100
success_pct = success_count / total * 100

print(f"Predictions (n={total}): Dropout={dropout_count} ({dropout_pct:.2f}%), Success={success_count} ({success_pct:.2f}%)")

# Plot
labels = [f"Dropout\n{dropout_count} ({dropout_pct:.1f}%)", f"Academic Success\n{success_count} ({success_pct:.1f}%)"]
sizes = [dropout_count, success_count]

plt.figure(figsize=(7,7))
patches, texts, autotexts = plt.pie(
    sizes,
    labels=labels,
    autopct='%1.1f%%',
    startangle=90,
    textprops={'fontsize': 12}
)
plt.title(f"Student Outcome Distribution â€” {best_model_name} (Acc: {best_accuracy:.2%})", fontsize=14)
plt.axis('equal')

# Ensure output directory exists, then save BEFORE plt.show()
out_dir = '/mnt/data'
os.makedirs(out_dir, exist_ok=True)
out_path = os.path.join(out_dir, 'student_outcome_prediction_piechart.png')

plt.savefig(out_path, dpi=150, bbox_inches='tight')
print(f"Pie chart saved to: {out_path}")

plt.show()

